---
title: "R Notebook"
output: html_notebook
---

# Re-running code from lab as a starting point

```{r, warning=F}
require(terra)
require(tidyterra)
require(sf)
require(adehabitatHR)
require(adehabitatLT)
require(adehabitatHS)
require(tidyverse)
require(survival)


#Import landcover tif
land = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week10/panther_landcover.tif')

#Reclassify the landcover tif
classification = read.table('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week10/landcover%20reclass.txt', header=T) 
land = classify(land, classification[,c(1,3)])
land = categories(land, value=unique(classification[,c(3,4)]))


#Import panther locations
panthers = st_read('/vsicurl/https://github.com/ValenteJJ/SpatialEcology/raw/main/Week10/panthers.shp') %>% 
  mutate(CatID = as.factor(CatID))

#Calculate wet forest focal statistic (5 km radius)
wetForest = land
values(wetForest) = 0
wetForest[land %in% c(10,12)] = 1
probMatrix = focalMat(wetForest, 5000, type='circle', fillNA=FALSE)
wetFocal = focal(wetForest, probMatrix, fun='sum', na.rm=T)


#Calculate dry forest focal statistic (5 km radius)
dryForest = land
values(dryForest) = 0
dryForest[land %in% c(11, 13)] = 1
probMatrix = focalMat(dryForest, 5000, type='circle', fillNA=FALSE)
dryFocal = focal(dryForest, probMatrix, fun='sum', na.rm=T)

#Stack together 
layers = c(land, wetFocal, dryFocal)
names(layers) = c('landcover', 'wetForest', 'dryForest')

#Recreate our used points object
use = terra::extract(layers, panthers) %>% 
  data.frame() %>% 
  mutate(CatID = as.factor(panthers$CatID)) %>% 
  group_by(CatID, landcover) %>%
  summarise(n = n()) %>% 
  ungroup() %>% 
  arrange(landcover) %>% 
  pivot_wider(names_from = landcover, values_from = n, values_fill=0) %>% 
  data.frame()
row.names(use) = use$CatID
use$CatID = NULL

#Recreate our available points object for a type II design
set.seed(8)
randII = spatSample(land, size=1000, as.points=T)
randIILand = data.frame(randII)

availII = randIILand %>% 
  group_by(Description2) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  rename(landcover = Description2) %>% 
  filter(!(is.na(landcover) | landcover=='Exotics')) %>% 
  pivot_wider(names_from = landcover, values_from = n)
```


# Challenge 1 (5 points)

In the lab, we estimated Manly's statistic (wi) values for a type II study design. We also fit a logistic regression for a type II study design. For this challenge, you're going to explore the relationship between wi values and beta values from a logistic regression model. Below I have recreated the analysis for producing wi values. I've also reconstructed the dataset we used for fitting the logistic regression models (allCovs).

Fit a new logistic regression model where use is a function of landcover-1 (the -1 removes the intercept from the fitted model). 
(A)Make sure this is the only covariate in the model. 
(B)Exponentiate the coefficients from the fitted model and compare them to the wi values calculated for each landcover type. 
  (B1)What do you notice? Explain the similarities and/or differences in how you would interpret the wi values and exponentiated coefficients.

```{r}
#Recreating the wi analysis
selRatioII = widesII(u = use, 
                     a = as.vector(as.matrix(availII)),
                     avknown = F,
                     alpha = 0.05)
selRatioII$wi

#Recreating the dataset for logistic regression
useCovs = terra::extract(layers, panthers) %>% 
  select(-ID) %>% 
  mutate(use=1)
backCovs = terra::extract(layers, randII) %>% 
  select(-ID) %>% 
  mutate(use=0)
allCovs = rbind(useCovs, backCovs) %>% 
  filter(!(is.na(landcover) | landcover=='Exotics')) %>% 
  mutate(landcover = as.factor(as.character(landcover)))
columns_to_remove = c("wetForest", "dryForest")
allCovs = allCovs[, !names(allCovs) %in% columns_to_remove]
#view(allCovs) #no other covariates

rsfAll = glm(use ~ landcover-1, family=binomial(link=logit), data=allCovs)

anova(rsfAll, test='LRT')
EXPcoef=exp(coef(rsfAll))#exponentiate the coefficients of the fitted model


#create Data Frame
EXPcoef.df = data.frame(
  'category' = names(EXPcoef),
  'coefficient' = EXPcoef)
#plot
EXPcoef.df = EXPcoef.df %>%
  arrange(desc(coefficient)) %>%
  mutate(category = factor(category, levels = category))

plot(EXPcoef.df, main="glm", xlab = "Landcover", ylab = "exp coefficient")
print("GLM exp coef")
print(EXPcoef)
print("wi")
print(selRatioII$wi)

```
while both the Exponentiated values of a linear regression and the output of the Manly's stastic provide an indication of the degree of use for each landcover type, outputs are interpreted differently. chat Gpt was used to help understand interpretation of the values of each model.
The exponentiated coefficients of the logistic regression describe the odds of use for each one-unit increase in landcover of a certain type. for example, for each one-unit increase in landcover Urban, the odds of occupancy for this cover type decrease by a factor of 0.03, and for each one-unit increase in dryForest, there is an increase in the odds of occupancy increase by a factor of 81.5. from this, we can see that wetForest and DryForest are much more likely to be used than any of the other landcover categories. 

The Manly statistic more directly measures the direction and strength of the association between probability of occupancy and landcover type. All values are positive, which means that as the amount of that landcover increases, the probablility of occupancy increases, which makes sense given that the data were collected from radiocollar-collected location data. about half of the values are below 1, which indicates a weak association, with Urban (0.08) being the weakest. the other values are above 1, with the larger values indicating a stronger association. here, Cypress Swamp has the probability of occupancy. the Linear regression predicted that Upland Forest would have strongest odds of occupancy. both models indicated that urban and open water have very low occupancy probability.





#################################################################################################
# Challenge 2 (5 points)

In the lab, we used the distribution of step lengths and turning angles to help us devise potential steps each individual could have taken at each point in time. 
  (A)Instead of step lengths, build a histogram representing the distribution of step speeds in km/hr. 
  (B)When and why might you choose to sample from a distribution of step speeds to calculate potential step lengths rather than drawing from the distribution of step lengths itself?

```{r}
# CODE FROM LAB

      #date from the recorded DOY
      substrRight = function(x, n){
        substr(x, nchar(x) - n+1, nchar(x))
      }
      
      #Hspatial object from our panthers sf object. converting the DOY information to a real date.
      panthersSp = panthers %>%
        mutate(Juldate = as.character(Juldate)) %>%
        mutate(date = as.numeric(substrRight(Juldate, 3))) %>%
        mutate(Date = as.Date(date, origin=as.Date("2006-01-01"))) %>%
        mutate(Date = as.POSIXct(Date, "%Y-%m-%d", tz='')) %>%
        as('Spatial')
      
      #trajectory object from the x-y coordinates and associated timestamps.
      pantherLtraj = as.ltraj(xy=coordinates(panthersSp), date=panthersSp$Date, id=panthersSp$CatID, typeII=T)
      plot(pantherLtraj)

      
      
# Extract Cat data for each catID
    catONE = pantherLtraj[[1]]
    catTWO = pantherLtraj[[2]]
    catTHREE = pantherLtraj[[3]]
    catFOUR = pantherLtraj[[4]]
    catFIVE = pantherLtraj[[5]]
    catSIX = pantherLtraj[[6]]
        print(catONE)#just checking to see if works the way I think
        print(catTWO)
        
    #Calculate speeds
      catONEspeed.kmh = (catONE[, "dist"]/1000) / (catONE[, "dt"]/3600)
      catTWOspeed.kmh = (catTWO[, "dist"]/1000) / (catTWO[, "dt"]/3600)
      catTHREEspeed.kmh = (catTHREE[, "dist"]/1000) / (catTHREE[, "dt"]/3600)
      catFOURspeed.kmh = (catFOUR[, "dist"]/1000) / (catFOUR[, "dt"]/3600)
      catFIVEspeed.kmh = (catFIVE[, "dist"]/1000) / (catFIVE[, "dt"]/3600)
      catSIXspeed.kmh = (catSIX[, "dist"]/1000) / (catSIX[, "dt"]/3600)

  # Combine 
  ALLspeed = c(catONEspeed.kmh, catTWOspeed.kmh, catTHREEspeed.kmh, catFOURspeed.kmh, catFIVEspeed.kmh, catSIXspeed.kmh)

#plot
hist(ALLspeed, main = "Panther Speeds", xlab = "Speed (km/hr)")
```
(B)when sampling from step lengths, you assume that the animal went in a linear fashion from point a to point b; however, this is often not the case, especially for a highly mobile animal like a bird. while calculating speed also assumes linear distance since you need distance traveled to calculate speed,they tell about different aspects of animal movement. this could be particularly useful for migratory species. Migrating whales in particular come to mind. you can find distance and speed of travel and can extrapolate to figure out how long until they reach their destination(if known). at the end of the day, it depends on what your research question is.

############################################################################################
# Challenge 3 (5 points)

Path straightness is a metric we can use to evaluate how tortuous of a path a tracked animal took from one point to another. We calculate straightness as the straight line distance between two points divided by the length of the path actually taken. The resulting straightness statistic takes a value between 0 and 1 where 1 indicates a straight line path and 0 represents an infinitely tortuous path.

For each of the 6 panthers, calculate the straightness of the path between the first and last point recorded. To do that, first 
calculate the numerator for each panther as the straight-line distance between the start and end points. HINT: the coordinates for each point are in UTMs (meters from the Equator and meters from the Prime Meridian). With the x and y coordinates for two different points, you can calculate their straight-line distance using the Pythagorean theorem.

Next calculate the denominator for each panther. To do this, you can simply sum all of the step distances for that particular individual.

Now divide the numerator by the denominator. Which panther took the most tortuous path? Which took the least tortuous path?

```{r}

stepData = data.frame(st_coordinates(panthers)) %>% 
  mutate(CatID = as.factor(panthers$CatID))
#view(stepData)

###FIND THE NUMERATOR
############# I GIVE UP TRYING TO UNDERSTAND FOR LOOPS######################
catONEnum = sqrt(((catONE$x[1]) - (catONE$x[length(catONE$x)]))^2 +
  ((catONE$y[1]) - (catONE$y[length(catONE$y)]))^2)
catTWOnum = sqrt(((catTWO$x[1]) - (catTWO$x[length(catTWO$x)]))^2 +
  ((catTWO$y[1]) - (catTWO$y[length(catTWO$y)]))^2)
catTHREEnum = sqrt(((catTHREE$x[1]) - (catTHREE$x[length(catTHREE$x)]))^2 +
  ((catTHREE$y[1]) - (catTHREE$y[length(catTHREE$y)]))^2)
catFOURnum = sqrt(((catFOUR$x[1]) - (catFOUR$x[length(catFOUR$x)]))^2 +
  ((catFOUR$y[1]) - (catFOUR$y[length(catFOUR$y)]))^2)
catFIVEnum = sqrt(((catFIVE$x[1]) - (catFIVE$x[length(catFIVE$x)]))^2 +
  ((catFIVE$y[1]) - (catFIVE$y[length(catFIVE$y)]))^2)
catSIXnum = sqrt(((catSIX$x[1]) - (catSIX$x[length(catSIX$x)]))^2 +
  ((catSIX$y[1]) - (catSIX$y[length(catSIX$y)]))^2)

###FIND DENOMINATORS
catONEdenom = sum(catONE$dist, na.rm = T)
catTWOdenom = sum(catTWO$dist, na.rm = T)
catTHREEdenom = sum(catTHREE$dist, na.rm = T)
catFOURdenom = sum(catFOUR$dist, na.rm = T)
catFIVEdenom = sum(catFIVE$dist, na.rm = T)
catSIXdenom = sum(catSIX$dist, na.rm = T)

# Calculate straightness
catONEstraight = catONEnum/catONEdenom
catTWOstraight = catTWOnum/catTWOdenom
catTHREEstraight = catTHREEnum/catTHREEdenom
catFOURstraight = catFOURnum/catFOURdenom
catFIVEstraight = catFIVEnum/catFIVEdenom
catSIXstraight = catSIXnum/catSIXdenom


# Create Data Frame to store info
straight = data.frame(
  CatID = c("Cat 1", "Cat 2", "Cat 3", "Cat 4", "Cat 5", "Cat 6"),
  Straightness = c(catONEstraight, catTWOstraight, catTHREEstraight,
                   catFOURstraight, catFIVEstraight, catSIXstraight)
)
print(straight)
```
length of path (straight line between endpoints) divided by the actual distance traveled means that a larger number is a more straight path. therefore, Panther 6 had the most straight path (such a goal-oriented queen) and panther one had the most winding path (that's okay too, king, we cant all be expected to know what we want in life right away).



#####################################################################################################################
# Challenge 4 (5 points)

(A)For each panther, calculate the frequency with which locations were recorded as points per day. 
(B)Plot path straightness as a function of frequency (there should be 6 points on this figure, one per panther). 
(C)What relationship do you notice between these two variables, and why might that pattern be occurring?

```{r}
#okay, so to figure out how many points were recorded each day, we need to divide the total number of points by the number of days that passed for each cat.

# Number of days passed
print(catSIX)
    catONE.Daydif = as.numeric(catONE$date[length(catONE$date)] - catONE$date[1])
    catTWO.Daydif = as.numeric(catTWO$date[length(catTWO$date)] - catTWO$date[2])
    catTHREE.Daydif = as.numeric(catTHREE$date[length(catTHREE$date)] - catTHREE$date[3])
    catFOUR.Daydif = as.numeric(catFOUR$date[length(catFOUR$date)] - catFOUR$date[4])
    catFIVE.Daydif = as.numeric(catFIVE$date[length(catFIVE$date)] - catFIVE$date[5])
    catSIX.Daydif = as.numeric(catSIX$date[length(catSIX$date)] - catSIX$date[6])

# Points Per Day
    catONE.PPD = (length(catONE$date))/catONE.Daydif
    catTWO.PPD = (length(catTWO$date))/catTWO.Daydif
    catTHREE.PPD = (length(catTHREE$date))/catTHREE.Daydif
    catFOUR.PPD = (length(catFOUR$date))/catFOUR.Daydif
    catFIVE.PPD = (length(catFIVE$date))/catFIVE.Daydif
    catSIX.PPD = (length(catSIX$date))/catSIX.Daydif

# data frame
    STRAIGHTNESSvPPD = data.frame(
      CatID = factor(c("Cat 1", "Cat 2", "Cat 3", "Cat 4", "Cat 5", "Cat 6")),
      PathStraightness = c(catONEstraight, catTWOstraight, catTHREEstraight, catFOURstraight, catFIVEstraight, catSIXstraight),
      PointsPerDay = c(catONE.PPD, catTWO.PPD, catTHREE.PPD, catFOUR.PPD, catFIVE.PPD, catSIX.PPD)
    )
print(STRAIGHTNESSvPPD)
# Plot path straightness as a function of points per day
      linear_model = lm(STRAIGHTNESSvPPD[,2] ~ STRAIGHTNESSvPPD[,3])
        slope = coef(linear_model)[2]
        intercept = coef(linear_model)[1]
      line = c(intercept, slope)

plot(STRAIGHTNESSvPPD[c(3,2)], main="Panther Path Straightness vs Frequency of Location data")
    abline(line)
plot(STRAIGHTNESSvPPD[c(1,2)], main="Path Straightness Value per Panther")
```

as the number of points per day increases, the path straightness generally increases with these panthers. I think we would need more panther data to draw a generalization. since path straightness is essentially the ratio of the straight-line distance between each panther's start and end points to the sum of all step distances (between each point)along the path of each panther. each step is the straight line distance between the points, thus adding more points can increase or decrease the  calculated path straightness depending on the straight line distance between endpoints and the total length of time.
